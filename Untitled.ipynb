{"cells": [{"metadata": {"trusted": true}, "cell_type": "code", "source": "import os\nos.system('pip install SimpleITK')\nos.system('pip install tensorboardX')\n\nfrom dataset.dataset_lits_val import Val_Dataset\nfrom dataset.dataset_lits_train import Train_Dataset\n\nfrom torch.utils.data import DataLoader\nimport torch\nimport torch.optim as optim\nfrom tqdm import tqdm\nimport config\n\nfrom models import UNet, ResUNet , KiUNet_min, SegNet\n\nfrom utils import logger, weights_init, metrics, common, loss\nimport os\nimport numpy as np\nfrom collections import OrderedDict\n\nimport moxing as mox\n\n\n\ndef val(model, val_loader, loss_func, n_labels):\n    model.eval()\n    val_loss = metrics.LossAverage()\n    val_dice = metrics.DiceAverage(n_labels)\n    with torch.no_grad():\n        for idx,(data, target) in tqdm(enumerate(val_loader),total=len(val_loader)):\n            data, target = data.float(), target.long()\n            target = common.to_one_hot_3d(target, n_labels)\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            loss=loss_func(output, target)\n            \n            val_loss.update(loss.item(),data.size(0))\n            val_dice.update(output, target)\n    val_log = OrderedDict({'Val_Loss': val_loss.avg, 'Val_dice_liver': val_dice.avg[1]})\n    if n_labels==3: val_log.update({'Val_dice_tumor': val_dice.avg[2]})\n    return val_log\n\ndef train(model, train_loader, optimizer, loss_func, n_labels, alpha):\n    print(\"=======Epoch:{}=======lr:{}\".format(epoch,optimizer.state_dict()['param_groups'][0]['lr']))\n    model.train()\n    train_loss = metrics.LossAverage()\n    train_dice = metrics.DiceAverage(n_labels)\n\n    for idx, (data, target) in tqdm(enumerate(train_loader),total=len(train_loader)):\n        data, target = data.float(), target.long()\n        target = common.to_one_hot_3d(target,n_labels)\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n\n        output = model(data)\n        loss0 = loss_func(output[0], target)\n        loss1 = loss_func(output[1], target)\n        loss2 = loss_func(output[2], target)\n        loss3 = loss_func(output[3], target)\n\n        loss = loss3  +  alpha * (loss0 + loss1 + loss2)\n        loss.backward()\n        optimizer.step()\n        \n        train_loss.update(loss3.item(),data.size(0))\n        train_dice.update(output[3], target)\n\n    val_log = OrderedDict({'Train_Loss': train_loss.avg, 'Train_dice_liver': train_dice.avg[1]})\n    if n_labels==3: val_log.update({'Train_dice_tumor': train_dice.avg[2]})\n    return val_log\n\nif __name__ == '__main__':\n    args = config.args\n    save_path = os.path.join('./experiments', args.save)\n    if not os.path.exists(save_path): os.mkdir(save_path)\n    device = torch.device('cpu' if args.cpu else 'cuda')\n    # data info\n    train_loader = DataLoader(dataset=Train_Dataset(args),batch_size=args.batch_size,num_workers=args.n_threads, shuffle=True)\n    val_loader = DataLoader(dataset=Val_Dataset(args),batch_size=2,num_workers=args.n_threads, shuffle=False)\n\n    # model info\n    model = ResUNet(in_channel=1, out_channel=args.n_labels,training=True).to(device)\n\n    model.apply(weights_init.init_model)\n    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n    common.print_network(model)\n    model = torch.nn.DataParallel(model, device_ids=args.gpu_id)  # multi-GPU\n \n    loss = loss.TverskyLoss()\n\n    log = logger.Train_Logger(save_path,\"train_log\")\n\n    best = [0,0] # \u521d\u59cb\u5316\u6700\u4f18\u6a21\u578b\u7684epoch\u548cperformance\n    trigger = 0  # early stop \u8ba1\u6570\u5668\n    alpha = 0.4 # \u6df1\u76d1\u7763\u8870\u51cf\u7cfb\u6570\u521d\u59cb\u503c\n    for epoch in range(1, args.epochs + 1):\n        common.adjust_learning_rate(optimizer, epoch, args)\n        train_log = train(model, train_loader, optimizer, loss, args.n_labels, alpha)\n        val_log = val(model, val_loader, loss, args.n_labels)\n        log.update(epoch,train_log,val_log)\n\n        # Save checkpoint.\n        state = {'net': model.state_dict(),'optimizer':optimizer.state_dict(),'epoch': epoch}\n        torch.save(state, os.path.join(save_path, 'latest_model.pth'))\n        trigger += 1\n        if val_log['Val_dice_liver'] > best[1]:\n            print('Saving best model')\n            torch.save(state, os.path.join(save_path, 'best_model.pth'))\n            best[0] = epoch\n            best[1] = val_log['Val_dice_liver']\n            trigger = 0\n        print('Best performance at Epoch: {} | {}'.format(best[0],best[1]))\n\n        # \u6df1\u76d1\u7763\u7cfb\u6570\u8870\u51cf\n        if epoch % 30 == 0: alpha *= 0.8\n\n        # early stopping\n        if args.early_stop is not None:\n            if trigger >= args.early_stop:\n                print(\"=> early stopping\")\n                break\n        torch.cuda.empty_cache()    ", "execution_count": null, "outputs": [{"output_type": "stream", "text": "INFO:root:Using MoXing-v2.0.0.rc0-19e4d3ab\nINFO:root:Using OBS-Python-SDK-3.20.9.1\n", "name": "stderr"}, {"output_type": "stream", "text": "ResUNet(\n  (encoder_stage1): Sequential(\n    (0): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n    (1): PReLU(num_parameters=16)\n    (2): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n    (3): PReLU(num_parameters=16)\n  )\n  (encoder_stage2): Sequential(\n    (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n    (1): PReLU(num_parameters=32)\n    (2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n    (3): PReLU(num_parameters=32)\n    (4): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n    (5): PReLU(num_parameters=32)\n  )\n  (encoder_stage3): Sequential(\n    (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n    (1): PReLU(num_parameters=64)\n    (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2))\n    (3): PReLU(num_parameters=64)\n    (4): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(4, 4, 4), dilation=(4, 4, 4))\n    (5): PReLU(num_parameters=64)\n  )\n  (encoder_stage4): Sequential(\n    (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(3, 3, 3), dilation=(3, 3, 3))\n    (1): PReLU(num_parameters=128)\n    (2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(4, 4, 4), dilation=(4, 4, 4))\n    (3): PReLU(num_parameters=128)\n    (4): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(5, 5, 5), dilation=(5, 5, 5))\n    (5): PReLU(num_parameters=128)\n  )\n  (decoder_stage1): Sequential(\n    (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n    (1): PReLU(num_parameters=256)\n    (2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n    (3): PReLU(num_parameters=256)\n    (4): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n    (5): PReLU(num_parameters=256)\n  )\n  (decoder_stage2): Sequential(\n    (0): Conv3d(192, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n    (1): PReLU(num_parameters=128)\n    (2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n    (3): PReLU(num_parameters=128)\n    (4): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n    (5): PReLU(num_parameters=128)\n  )\n  (decoder_stage3): Sequential(\n    (0): Conv3d(96, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n    (1): PReLU(num_parameters=64)\n    (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n    (3): PReLU(num_parameters=64)\n    (4): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n    (5): PReLU(num_parameters=64)\n  )\n  (decoder_stage4): Sequential(\n    (0): Conv3d(48, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n    (1): PReLU(num_parameters=32)\n    (2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n    (3): PReLU(num_parameters=32)\n  )\n  (down_conv1): Sequential(\n    (0): Conv3d(16, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n    (1): PReLU(num_parameters=32)\n  )\n  (down_conv2): Sequential(\n    (0): Conv3d(32, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n    (1): PReLU(num_parameters=64)\n  )\n  (down_conv3): Sequential(\n    (0): Conv3d(64, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n    (1): PReLU(num_parameters=128)\n  )\n  (down_conv4): Sequential(\n    (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n    (1): PReLU(num_parameters=256)\n  )\n  (up_conv2): Sequential(\n    (0): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n    (1): PReLU(num_parameters=128)\n  )\n  (up_conv3): Sequential(\n    (0): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n    (1): PReLU(num_parameters=64)\n  )\n  (up_conv4): Sequential(\n    (0): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n    (1): PReLU(num_parameters=32)\n  )\n  (map4): Sequential(\n    (0): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n    (1): Upsample(scale_factor=(1.0, 1.0, 1.0), mode=trilinear)\n    (2): Softmax(dim=1)\n  )\n  (map3): Sequential(\n    (0): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n    (1): Upsample(scale_factor=(2.0, 2.0, 2.0), mode=trilinear)\n    (2): Softmax(dim=1)\n  )\n  (map2): Sequential(\n    (0): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n    (1): Upsample(scale_factor=(4.0, 4.0, 4.0), mode=trilinear)\n    (2): Softmax(dim=1)\n  )\n  (map1): Sequential(\n    (0): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n    (1): Upsample(scale_factor=(8.0, 8.0, 8.0), mode=trilinear)\n    (2): Softmax(dim=1)\n  )\n)\nTotal number of parameters: 9498744\n=======Epoch:1=======lr:0.0001\n", "name": "stdout"}, {"output_type": "stream", "text": "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 44/44 [03:12<00:00,  4.38s/it]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 12/12 [00:44<00:00,  3.68s/it]\n", "name": "stderr"}, {"output_type": "stream", "text": "\u001b[0;33mTrain:\u001b[0m OrderedDict([('Train_Loss', 0.2458), ('Train_dice_liver', 0.5516)])\n\u001b[0;33mValid:\u001b[0m OrderedDict([('Val_Loss', 0.1318), ('Val_dice_liver', 0.7286)])\nSaving best model\nBest performance at Epoch: 1 | 0.7286\n=======Epoch:2=======lr:0.0001\n", "name": "stdout"}, {"output_type": "stream", "text": "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 44/44 [03:05<00:00,  4.21s/it]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 12/12 [00:43<00:00,  3.66s/it]", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "from torch.utils.data import DataLoader\nimport torch\nfrom tqdm import tqdm\nimport config\nfrom utils import logger,common\nfrom dataset.dataset_lits_test import Test_Datasets,to_one_hot_3d\nimport SimpleITK as sitk\nimport os\nimport numpy as np\nfrom models import ResUNet\nfrom utils.metrics import DiceAverage\nfrom collections import OrderedDict\n\nresult_dice = 0.0\nnumber_dice = 0\n\ndef predict_one_img(model, img_dataset, args):\n    dataloader = DataLoader(dataset=img_dataset, batch_size=1, num_workers=0, shuffle=False)\n    model.eval()\n    test_dice = DiceAverage(args.n_labels)\n    target = to_one_hot_3d(img_dataset.label, args.n_labels)\n    \n    with torch.no_grad():\n        for data in tqdm(dataloader,total=len(dataloader)):\n            data = data.to(device)\n            output = model(data)\n            # output = nn.functional.interpolate(output, scale_factor=(1//args.slice_down_scale,1//args.xy_down_scale,1//args.xy_down_scale), mode='trilinear', align_corners=False) # \u7a7a\u95f4\u5206\u8fa8\u7387\u6062\u590d\u5230\u539f\u59cbsize\n            img_dataset.update_result(output.detach().cpu())\n\n    pred = img_dataset.recompone_result()\n    pred = torch.argmax(pred,dim=1)\n\n    pred_img = common.to_one_hot_3d(pred,args.n_labels)\n  \n    test_dice.update(pred_img, target)\n    \n    test_dice = OrderedDict({'Dice_liver': test_dice.avg[1]})\n    number_dice = number_dice + 1\n    result_dice = result_dice + test_dice.avg[1]\n    \n    if args.n_labels==3: test_dice.update({'Dice_tumor': test_dice.avg[2]})\n    \n    pred = np.asarray(pred.numpy(),dtype='uint8')\n    if args.postprocess:\n        pass # TO DO\n    pred = sitk.GetImageFromArray(np.squeeze(pred,axis=0))\n\n    return test_dice, pred\n\nif __name__ == '__main__':\n    args = config.args\n    save_path = os.path.join('./experiments', args.save)\n    device = torch.device('cpu' if args.cpu else 'cuda')\n    # model info\n    model = ResUNet(in_channel=1, out_channel=args.n_labels,training=False).to(device)\n    model = torch.nn.DataParallel(model, device_ids=args.gpu_id)  # multi-GPU\n    ckpt = torch.load('{}/best_model.pth'.format(save_path))\n    model.load_state_dict(ckpt['net'])\n\n    test_log = logger.Test_Logger(save_path,\"test_log\")\n    # data info\n    result_save_path = '{}/result'.format(save_path)\n    if not os.path.exists(result_save_path):\n        os.mkdir(result_save_path)\n    #args.test_data_path'./fixed_data/test_pre'\n    datasets = Test_Datasets(args.test_data_path,args=args)\n    for img_dataset,file_idx in datasets:\n        test_dice,pred_img = predict_one_img(model, img_dataset, args)\n        test_log.update(file_idx, test_dice)\n        sitk.WriteImage(pred_img, os.path.join(result_save_path, 'result-'+file_idx+'.gz'))\n    \n    print('RESULT DICE:',result_dice/number_dice)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "import os\nprint(os.getcwd())\nprint(os.listdir())", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pytorch-1.4.0", "display_name": "Pytorch-1.4.0", "language": "python"}, "language_info": {"name": "python", "version": "3.6.4", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}